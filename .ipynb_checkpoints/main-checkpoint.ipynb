{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4edda583-af9a-42cc-a77e-ee29aca40678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\tornikeo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.16.0)\n",
      "Requirement already satisfied: pandas>=1.2.3 in c:\\users\\tornikeo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (1.2.4)\n",
      "Requirement already satisfied: pandas-stubs>=1.1.0.11 in c:\\users\\tornikeo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (1.2.0.57)\n",
      "Requirement already satisfied: openpyxl>=3.0.7 in c:\\users\\tornikeo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (3.0.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\tornikeo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (4.62.3)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\tornikeo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (2.27.1)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\tornikeo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\tornikeo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=1.2.3->openai) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\tornikeo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=1.2.3->openai) (1.19.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\tornikeo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tornikeo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\tornikeo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.20->openai) (2.0.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tornikeo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.20->openai) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\tornikeo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.20->openai) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tornikeo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.20->openai) (2021.10.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\tornikeo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm->openai) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'c:\\users\\tornikeo\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install -U openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9ba7d5c-e3e7-4c5c-8a09-4ca4845a1799",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "import os\n",
    "import openai\n",
    "config = dotenv_values(\".env\")\n",
    "openai.api_key = config['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd41ee69-bd07-4eec-abd6-486c79c33e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'When you find something solid, use it, and let it expand horizontally into a whole environment.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'These are quiet scenes. Not silent but quiet. You should have a short verbal exchange in each place.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Hold on. Slow down and make sure something happens that signals the beginning of a scene before you move on.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Pure horizontal movement now. Just tumble along.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"I love this. But help other people see what's going on. Expand the physicality of each situation.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Now do some vertical exploration before you move on.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Be the over-enthusiastic, therapeutic host. Everything the person requests, no matter how dry, is an opportunity to offer unsolicited therapy.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_prompts = '''\n",
    "1. When you find something solid, use it, and let it expand horizontally into a whole environment.\n",
    "\n",
    "2. These are quiet scenes. Not silent but quiet. You should have a short verbal exchange in each place.\n",
    "\n",
    "3. Hold on. Slow down and make sure something happens that signals the beginning of a scene before you move on.\n",
    "\n",
    "4. Pure horizontal movement now. Just tumble along.\n",
    "\n",
    "5. I love this. But help other people see what's going on. Expand the physicality of each situation.\n",
    "\n",
    "6. Now do some vertical exploration before you move on.\n",
    "\n",
    "7. Be the over-enthusiastic, therapeutic host. Everything the person requests, no matter how dry, is an opportunity to offer unsolicited therapy.\n",
    "'''\n",
    "from IPython.display import display\n",
    "\n",
    "prompts = []\n",
    "for prompt in raw_prompts.split('\\n'):\n",
    "    prompt = prompt.strip()\n",
    "    if len(prompt):\n",
    "        prompt = prompt[3:]\n",
    "        display(prompt)\n",
    "        prompts.append(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b475c37-edbf-4710-a3ae-50195b0b4315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm \n",
    "\n",
    "def assure_ends_with_dot(prompt):\n",
    "    prompt = prompt.strip().replace('.','')\n",
    "    prompt = prompt + '.' if prompt[-1] != '.' else prompt\n",
    "    return prompt\n",
    "\n",
    "def generate_alternative_wording(prompts):\n",
    "    result = []\n",
    "    for prompt in tqdm.tqdm(prompts):\n",
    "        prompt = assure_ends_with_dot(prompt)\n",
    "        alternative_wording = generate_alternative_wording_once(\n",
    "            prompt,\n",
    "            num_translated=2,\n",
    "            num_back=2,\n",
    "        )\n",
    "        result += [(prompt, alternative_wording)]\n",
    "    return result\n",
    "\n",
    "def generate_alternative_wording_once(\n",
    "    prompt,\n",
    "    temp = .5,\n",
    "    num_translated=1, \n",
    "    num_back=1,):\n",
    "    query = ('Translate to Spanish')\n",
    "    tokens = len(prompt.split()) * 3 // 4 + 1\n",
    "    response_translated = openai.Completion.create(\n",
    "        engine=\"davinci\",\n",
    "        prompt=f\"{query}:\\n\\n{prompt}\",\n",
    "        temperature=temp,\n",
    "        max_tokens=tokens,\n",
    "        top_p=1.0,\n",
    "        n = num_translated,\n",
    "        frequency_penalty=1.0,\n",
    "        presence_penalty=1.0,\n",
    "    )\n",
    "    # print(response_translated)\n",
    "    results = []\n",
    "    for choice in response_translated['choices']:\n",
    "        prompt = choice['text']\n",
    "        query = ('Translate to English')\n",
    "        # prompt = assure_ends_with_dot(prompt)\n",
    "        response = openai.Completion.create(\n",
    "            engine=\"davinci\",\n",
    "            prompt=f\"{query}:\\n\\n{prompt}\",\n",
    "            temperature=temp,\n",
    "            max_tokens=tokens,\n",
    "            top_p=1.0,\n",
    "            n = num_back,\n",
    "            frequency_penalty=1.0,\n",
    "            presence_penalty=1.0,\n",
    "        )\n",
    "        results += [choice['text'].strip()\n",
    "                    for choice in response['choices']]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de0eb426-d0b0-4c4c-af16-5ea11e806991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject edit at 0x21b79e55c20> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"text\": \"Find something that works, and then use it. Try to let this fundamental building block allow you to build horizontally into a greater and more fully developed environment.\\n\\nBesides what you see, it may be interesting to dig deeper and look at the notes of the sections in the code area of my personal website at http://file.hoffman.ws, in particular the about and code sections.\\n\"\n",
       "    },\n",
       "    {\n",
       "      \"index\": 1,\n",
       "      \"text\": \"When you find a set of protocols that works well, start from that solid base, and make it grow horizontally into a whole environment.\\n\"\n",
       "    },\n",
       "    {\n",
       "      \"index\": 2,\n",
       "      \"text\": \"When you encounter a somewhat well-structured aspect of your code, use it, and let it expand and deepen into a environment with a placement in your application.\\n\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1649261150,\n",
       "  \"object\": \"edit\"\n",
       "}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Edit.create(\n",
    "    engine=\"text-davinci-edit-001\",\n",
    "    input=\"When you find something solid, use it, and let it expand horizontally into a whole environment.\",\n",
    "    instruction=\"Paraphrase and be extremely verbose.\",\n",
    "    temperature=1,\n",
    "    top_p=1,\n",
    "    n=3,\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c916ac86-8b07-47f4-86c4-ad114e94d4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|████████████████████████████████████████████████████████████                        | 5/7 [00:31<00:12,  6.40s/it]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(prompts):\n\u001b[0;32m      3\u001b[0m     response \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mEdit\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m      4\u001b[0m         engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-davinci-edit-001\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m         n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m     10\u001b[0m     )\n\u001b[1;32m---> 11\u001b[0m     result \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [(prompt, [txt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m txt \u001b[38;5;129;01min\u001b[39;00m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m]])]\n",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(prompts):\n\u001b[0;32m      3\u001b[0m     response \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mEdit\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m      4\u001b[0m         engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-davinci-edit-001\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m         n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m     10\u001b[0m     )\n\u001b[1;32m---> 11\u001b[0m     result \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [(prompt, [\u001b[43mtxt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m txt \u001b[38;5;129;01min\u001b[39;00m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m]])]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'text'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65eaeafa-a944-4724-9ba5-42dc36ae9688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject edit at 0x21b16da2090> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"error\": {\n",
       "        \"message\": \"Could not edit text. Please sample again or try with a different temperature setting, input, or instruction.\",\n",
       "        \"type\": \"invalid_edit\"\n",
       "      },\n",
       "      \"index\": 0\n",
       "    },\n",
       "    {\n",
       "      \"index\": 1,\n",
       "      \"text\": \"An attempt to paraphrase and be extremely verbose about it.\\n\"\n",
       "    },\n",
       "    {\n",
       "      \"index\": 2,\n",
       "      \"text\": \"Now you need to spend some time doing vertical exploration before you move on.\\n\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1649261390,\n",
       "  \"object\": \"edit\"\n",
       "}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fda8d31-cbb0-460c-abbd-ae8d8824cddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:20<00:00,  2.92s/it]\n"
     ]
    }
   ],
   "source": [
    "results = generate_alternative_wording(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9f08261-3027-4e42-9661-104a672c49f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOU SAY:  When you find something solid, use it, and let it expand horizontally into a whole environment.\n",
      "============================== MODEL SAYS: ==============================\n",
      "1 .  serious, problem with this approach is that it requires all the services\n",
      "2 .  important, reason for my visit to the island was because I wanted\n",
      "3 .  .\n",
      "\n",
      "\n",
      "\n",
      "Translate to English:\n",
      "\n",
      "\n",
      "\n",
      "The\n",
      "4 .  . You will be able to create a new room in the basement\n",
      "============================== END: ==============================\n",
      "YOU SAY:  These are quiet scenes Not silent but quiet You should have a short verbal exchange in each place.\n",
      "============================== MODEL SAYS: ==============================\n",
      "1 .  are not actors. They are real reenactors, who take\n",
      "2 .  are not actors. They are real reenactors of the Civil\n",
      "3 .  English: The characters should not speak in a whisper.\n",
      "\n",
      "Trans\n",
      "4 .  English:\n",
      "\n",
      " The characters should not speak in a whisper.\n",
      "============================== END: ==============================\n",
      "YOU SAY:  Hold on Slow down and make sure something happens that signals the beginning of a scene before you move on.\n",
      "============================== MODEL SAYS: ==============================\n",
      "1 .  the page is finished loading.\n",
      "\n",
      "This translation has been viewed 637 times\n",
      "2 .  the page is fully loaded.\n",
      "\n",
      "You are able to navigate through the pages\n",
      "3 .  hurry, the text in your clipboard will be automatically translated.\n",
      "4 .  hurry to buy the first car you see. The Internet is a great place for\n",
      "============================== END: ==============================\n",
      "YOU SAY:  Pure horizontal movement now Just tumble along.\n",
      "============================== MODEL SAYS: ==============================\n",
      "1 .  .\n",
      "\n",
      "The second movement\n",
      "2 .  , and I'm thinking about\n",
      "3 .  :\n",
      "\n",
      "\n",
      "\n",
      "Translate\n",
      "4 .  :\n",
      "\n",
      "\n",
      "\n",
      "Translate\n",
      "============================== END: ==============================\n",
      "YOU SAY:  I love this But help other people see what's going on Expand the physicality of each situation.\n",
      "============================== MODEL SAYS: ==============================\n",
      "1 .  to see the full text\n",
      "\n",
      "Hugh Grant and Colin F\n",
      "2 .  it\n",
      "3 .  I don't like that It's good for you I'm not\n",
      "4 .  ternut Squash Soup with Coconut Cream. You can make it\n",
      "============================== END: ==============================\n",
      "YOU SAY:  Now do some vertical exploration before you move on.\n",
      "============================== MODEL SAYS: ==============================\n",
      "1 .  Translate to French\n",
      "2 .  Translate to French\n",
      "3 .  , left, right) and go\n",
      "4 .  , left, or right) and\n",
      "============================== END: ==============================\n",
      "YOU SAY:  Be the over-enthusiastic, therapeutic host Everything the person requests, no matter how dry, is an opportunity to offer unsolicited therapy.\n",
      "============================== MODEL SAYS: ==============================\n",
      "1 .  ’ll bring you a glass of water.”\n",
      "\n",
      "\n",
      "Translate\n",
      "2 .  will give you a glass of water.”\n",
      "\n",
      "Translate to English\n",
      "3 .  I’m so anxious, too. I have a lot of anxiety about\n",
      "4 .  I’m so anxious about my job too. I’ve been\n",
      "============================== END: ==============================\n"
     ]
    }
   ],
   "source": [
    "for orig,gens in results:\n",
    "    print('YOU SAY: ', orig)    \n",
    "    print('='*30, 'MODEL SAYS:','='*30)\n",
    "    for i,gen in enumerate(gens):\n",
    "        print(i+1, '. ', gen)\n",
    "        \n",
    "    print('='*30, 'END:','='*30)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac1abbd0-fd46-4269-895b-d95903f2691c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hold on. Slow down and make sure something happens that signals the beginning of a scene before you move on.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b8af4f8e-a8ca-4a4c-8682-0dd0df7dff34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:37<00:00,  5.31s/it]\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for prompt in tqdm.tqdm(prompts):\n",
    "    response = openai.Edit.create(\n",
    "        engine=\"text-davinci-edit-001\",\n",
    "        input=prompt,\n",
    "        instruction=\"Paraphrase extremely verbosely.\",\n",
    "        temperature=1,\n",
    "        top_p=1,\n",
    "        n=3,\n",
    "    )\n",
    "    texts = []\n",
    "    for choice in response['choices']:\n",
    "        if 'text' in choice.keys():\n",
    "            texts.append(choice['text'].strip())\n",
    "    result += [(prompt, texts)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ce4a469e-db7d-4f4b-8958-f7ef18b77701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOU SAY:  When you find something solid, use it, and let it expand horizontally into a whole environment.\n",
      "============================== MODEL SAYS: ==============================\n",
      "1 .  If you chew wholeheartedly at anything, it will tend to expand under its own weight, or mix with other dynamics around it.\n",
      "\n",
      "If you walk away from one fish, you are likely to be caught in the same trap.\n",
      "Bait and jigging hooks belong to the same universal dynamic.\n",
      "\n",
      "Fixed focus.\n",
      "Why, does it change its brain?  Who cares?\n",
      "It is enough to know that it works reliably but dangerously.\n",
      "When you find something solid, use it, and let it expand horizontally into a whole environment.\n",
      "2 .  Often basic ideas communicate best, but just as often some sort of expansion is necessary to communicate more widely.\n",
      "3 .  Find something solid, use it and let it spread up and down into a forementioned environment.\n",
      "============================== END: ==============================\n",
      "YOU SAY:  These are quiet scenes. Not silent but quiet. You should have a short verbal exchange in each place.\n",
      "============================== MODEL SAYS: ==============================\n",
      "1 .  These are quiet scenes. Not silent but quiet. You should have a short verbal exchange in each place.\n",
      "\n",
      "\tCharles: Thanks Beverly. This is... here we are. (pounds his fist on door) Come on come on!\n",
      "\t\n",
      "\tDana: No getting past you.\n",
      "\n",
      "\tKaufmann: I am a kuh-kuh-kuh-kuh-kaus-a-a-h-h-h-h-h-h-h-uh-ahhh. So sorry to keep you Beth but, to be perfectly honest... I've been avoiding you.\n",
      "\t\n",
      "\tBurnes: No what really bugs me is how you can anticipate something so impossibly. \n",
      "\t\n",
      "\tMuch to hos boss's horror, he runs out of the station, takes off his clothes, and pales into a skull. Then he starts floating in the air in his discarded clothes.\n",
      "\n",
      "\tBarney: Mmm.\n",
      "\n",
      "\tStathis chokes.\n",
      "2 .  The following scenes are quiet. Not silent but quiet. I propose that we create a very brief verbal exchange in each quiet scene.\n",
      "3 .  You should have a short verbal exchange in each place.\n",
      "Try to be aware of your surroundings to make the experience better.\n",
      "No place is silent, there is noise all around us but we can appreciate places that are quiet more easily.\n",
      "Notice how other people are reacting around you, too.\n",
      "Be careful not to be *too* obvious, though. We don't want to draw unwanted attention to ourselves.\n",
      "============================== END: ==============================\n",
      "YOU SAY:  Hold on. Slow down and make sure something happens that signals the beginning of a scene before you move on.\n",
      "============================== MODEL SAYS: ==============================\n",
      "1 .  Slow Down--Hold On.\n",
      "Slow down and make sure something happens that signals the beginning of a scene before you move on.\n",
      "2 .  Slow down and make it certain that something happens that signals the beginning of a scene before you move on.\n",
      "============================== END: ==============================\n",
      "YOU SAY:  Pure horizontal movement now. Just tumble along.\n",
      "============================== MODEL SAYS: ==============================\n",
      "1 .  ## Pure horizontal movement now. Just tumble along.\n",
      "2 .  Pure horizontal movement now. Just tumble along.\n",
      "\n",
      "This text was necessitated because paraphrasing, while somewhat optional, is nevertheless the\n",
      "richer choice.\n",
      "3 .  Put ExtremelyVertbose.py and buildOutput/doc into a folder of your choice as this does NOT maintain a current directory relative to paltform, since windows paths don't allow the forward slash common in *inux.\n",
      "============================== END: ==============================\n",
      "YOU SAY:  I love this. But help other people see what's going on. Expand the physicality of each situation.\n",
      "============================== MODEL SAYS: ==============================\n",
      "1 .  + We love this work and appreciate the effort at verbalizing, but we're not all R&D people familiar with the ins and outs of these projects, or invested in knowing about them. What we are invested in are films, and some of us have an interest in looking backward and learning about film history. How can you make this language dig deeper on the story side? \n",
      "+ Create interest by expanding physicality of each situation, developing more fully each of the emotional/physical/mental states that unfolds one of these film histories.  \n",
      "+ Involving more of the visceral qualities at play will make this material more accessible and entertaining to a general film audience. \n",
      "+ If this activity is a form of translation (from one medium to another, historical and technical to the experienced and emotional), then the flow of the translation depends on where and how it's going to live, how it's going to be integrated with other elements of the EYE site, for example ...  \n",
      "+ How does this piece complement the other technical and historical pieces? Does it revolve around anchor pieces now in the collection? Do others work around progressive and radical film practices/organizations (like the Miskwoski piece -- and what about its physical layout?) You might consider other modes for the EYE's storytelling.\n",
      "2 .  I love this. But help other people see what's going on. Expand the physicality of each situation.\n",
      "\n",
      "# https://jvns.ca/blog/2015/09/21/clear-explanations-of-tables-vs-tables/\n",
      "\n",
      "On a whiteboard in front of me, I will write 1 thing: the new verbose version of something you might think is difficult. Nowhere in this file will I try to pander to those who do not care, _____ how amusingly condescending I may write to them. (Not relevant.) And to prevent future accidental, inevitable obscurity and illegibility, I will make the explanation dense. But, here's the thing; all of this happens as I talk. No amount of density in a physical argument can match that quality about someone telling you, with words and gestures and metaphors, what's going on.\n",
      "\n",
      "In programming the size of an app is basically the strangeness of things you have to know before it make sense to you.\n",
      "3 .  I love this. But help other people see what's going on. Expand the physicality of each situation.\n",
      "The window flew into place and arrived in proximity to my face.\n",
      "============================== END: ==============================\n",
      "YOU SAY:  Now do some vertical exploration before you move on.\n",
      "============================== MODEL SAYS: ==============================\n",
      "1 .  Run several shells, and then change directories in each.\n",
      "2 .  The last step is to \"go forth and git\", which can be done after you've had a chance to do some vertical exploration on your own.\n",
      "3 .  A vertical exploration is defined to be the exploration of those commits which are higher than the current state of the document.\n",
      "Thus, the status of the HEAD is compared in the commit graph to compute this subset of commits.\n",
      "============================== END: ==============================\n",
      "YOU SAY:  Be the over-enthusiastic, therapeutic host. Everything the person requests, no matter how dry, is an opportunity to offer unsolicited therapy.\n",
      "============================== MODEL SAYS: ==============================\n",
      "1 .  Offering something as a response isn't usually as therapeutic as listening.\n",
      "2 .  The ideal host is optimistic, even to a fault.\n",
      "3 .  Be an oversuspicious host.\n",
      "Take, for example, blunt questions as of an opportuniy to offer pesky therapy.\n",
      "============================== END: ==============================\n"
     ]
    }
   ],
   "source": [
    "for orig,gens in result:\n",
    "    print('YOU SAY: ', orig)    \n",
    "    print('='*30, 'MODEL SAYS:','='*30)\n",
    "    for i,gen in enumerate(gens):\n",
    "        print(i+1, '. ', gen)\n",
    "    print('='*30, 'END:','='*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3782a8a-99fb-4995-917c-5c262d98475d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
