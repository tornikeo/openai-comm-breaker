{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4edda583-af9a-42cc-a77e-ee29aca40678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\tornikeo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.16.0)\n",
      "Requirement already satisfied: pandas>=1.2.3 in c:\\users\\tornikeo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (1.2.4)\n",
      "Requirement already satisfied: pandas-stubs>=1.1.0.11 in c:\\users\\tornikeo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (1.2.0.57)\n",
      "Requirement already satisfied: openpyxl>=3.0.7 in c:\\users\\tornikeo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (3.0.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\tornikeo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (4.62.3)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\tornikeo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openai) (2.27.1)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\tornikeo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\tornikeo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=1.2.3->openai) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\tornikeo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=1.2.3->openai) (1.19.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\tornikeo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\tornikeo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\tornikeo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.20->openai) (2.0.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\tornikeo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.20->openai) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\tornikeo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.20->openai) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tornikeo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests>=2.20->openai) (2021.10.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\tornikeo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm->openai) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'c:\\users\\tornikeo\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "pip install -U openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9ba7d5c-e3e7-4c5c-8a09-4ca4845a1799",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "import os\n",
    "import openai\n",
    "config = dotenv_values(\".env\")\n",
    "openai.api_key = config['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd41ee69-bd07-4eec-abd6-486c79c33e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'When you find something solid, use it, and let it expand horizontally into a whole environment.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'These are quiet scenes. Not silent but quiet. You should have a short verbal exchange in each place.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Hold on. Slow down and make sure something happens that signals the beginning of a scene before you move on.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Pure horizontal movement now. Just tumble along.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"I love this. But help other people see what's going on. Expand the physicality of each situation.\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Now do some vertical exploration before you move on.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Be the over-enthusiastic, therapeutic host. Everything the person requests, no matter how dry, is an opportunity to offer unsolicited therapy.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "raw_prompts = '''\n",
    "1. When you find something solid, use it, and let it expand horizontally into a whole environment.\n",
    "\n",
    "2. These are quiet scenes. Not silent but quiet. You should have a short verbal exchange in each place.\n",
    "\n",
    "3. Hold on. Slow down and make sure something happens that signals the beginning of a scene before you move on.\n",
    "\n",
    "4. Pure horizontal movement now. Just tumble along.\n",
    "\n",
    "5. I love this. But help other people see what's going on. Expand the physicality of each situation.\n",
    "\n",
    "6. Now do some vertical exploration before you move on.\n",
    "\n",
    "7. Be the over-enthusiastic, therapeutic host. Everything the person requests, no matter how dry, is an opportunity to offer unsolicited therapy.\n",
    "'''\n",
    "from IPython.display import display\n",
    "\n",
    "prompts = []\n",
    "for prompt in raw_prompts.split('\\n'):\n",
    "    prompt = prompt.strip()\n",
    "    if len(prompt):\n",
    "        prompt = prompt[3:]\n",
    "        display(prompt)\n",
    "        prompts.append(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b475c37-edbf-4710-a3ae-50195b0b4315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm \n",
    "\n",
    "def assure_ends_with_dot(prompt):\n",
    "    prompt = prompt.strip().replace('.','')\n",
    "    prompt = prompt + '.' if prompt[-1] != '.' else prompt\n",
    "    return prompt\n",
    "\n",
    "def generate_alternative_wording(prompts):\n",
    "    result = []\n",
    "    for prompt in tqdm.tqdm(prompts):\n",
    "        prompt = assure_ends_with_dot(prompt)\n",
    "        alternative_wording = generate_alternative_wording_once(\n",
    "            prompt,\n",
    "            num_translated=2,\n",
    "            num_back=2,\n",
    "        )\n",
    "        result += [(prompt, alternative_wording)]\n",
    "    return result\n",
    "\n",
    "def generate_alternative_wording_once(\n",
    "    prompt,\n",
    "    temp = .5,\n",
    "    num_translated=1, \n",
    "    num_back=1,):\n",
    "    query = ('Translate to Spanish')\n",
    "    tokens = len(prompt.split()) * 3 // 4 + 1\n",
    "    response_translated = openai.Completion.create(\n",
    "        engine=\"davinci\",\n",
    "        prompt=f\"{query}:\\n\\n{prompt}\",\n",
    "        temperature=temp,\n",
    "        max_tokens=tokens,\n",
    "        top_p=1.0,\n",
    "        n = num_translated,\n",
    "        frequency_penalty=1.0,\n",
    "        presence_penalty=1.0,\n",
    "    )\n",
    "    # print(response_translated)\n",
    "    results = []\n",
    "    for choice in response_translated['choices']:\n",
    "        prompt = choice['text']\n",
    "        query = ('Translate to English')\n",
    "        # prompt = assure_ends_with_dot(prompt)\n",
    "        response = openai.Completion.create(\n",
    "            engine=\"davinci\",\n",
    "            prompt=f\"{query}:\\n\\n{prompt}\",\n",
    "            temperature=temp,\n",
    "            max_tokens=tokens,\n",
    "            top_p=1.0,\n",
    "            n = num_back,\n",
    "            frequency_penalty=1.0,\n",
    "            presence_penalty=1.0,\n",
    "        )\n",
    "        results += [choice['text'].strip()\n",
    "                    for choice in response['choices']]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de0eb426-d0b0-4c4c-af16-5ea11e806991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject edit at 0x21b79e55c20> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"index\": 0,\n",
       "      \"text\": \"Find something that works, and then use it. Try to let this fundamental building block allow you to build horizontally into a greater and more fully developed environment.\\n\\nBesides what you see, it may be interesting to dig deeper and look at the notes of the sections in the code area of my personal website at http://file.hoffman.ws, in particular the about and code sections.\\n\"\n",
       "    },\n",
       "    {\n",
       "      \"index\": 1,\n",
       "      \"text\": \"When you find a set of protocols that works well, start from that solid base, and make it grow horizontally into a whole environment.\\n\"\n",
       "    },\n",
       "    {\n",
       "      \"index\": 2,\n",
       "      \"text\": \"When you encounter a somewhat well-structured aspect of your code, use it, and let it expand and deepen into a environment with a placement in your application.\\n\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1649261150,\n",
       "  \"object\": \"edit\"\n",
       "}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.Edit.create(\n",
    "    engine=\"text-davinci-edit-001\",\n",
    "    input=\"When you find something solid, use it, and let it expand horizontally into a whole environment.\",\n",
    "    instruction=\"Paraphrase and be extremely verbose.\",\n",
    "    temperature=1,\n",
    "    top_p=1,\n",
    "    n=3,\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c916ac86-8b07-47f4-86c4-ad114e94d4dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|████████████████████████████████████████████████████████████                        | 5/7 [00:31<00:12,  6.40s/it]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(prompts):\n\u001b[0;32m      3\u001b[0m     response \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mEdit\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m      4\u001b[0m         engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-davinci-edit-001\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m         n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m     10\u001b[0m     )\n\u001b[1;32m---> 11\u001b[0m     result \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [(prompt, [txt[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m txt \u001b[38;5;129;01min\u001b[39;00m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m]])]\n",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(prompts):\n\u001b[0;32m      3\u001b[0m     response \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mEdit\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m      4\u001b[0m         engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-davinci-edit-001\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m         n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m     10\u001b[0m     )\n\u001b[1;32m---> 11\u001b[0m     result \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [(prompt, [\u001b[43mtxt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mstrip() \u001b[38;5;28;01mfor\u001b[39;00m txt \u001b[38;5;129;01min\u001b[39;00m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m]])]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'text'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65eaeafa-a944-4724-9ba5-42dc36ae9688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject edit at 0x21b16da2090> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"error\": {\n",
       "        \"message\": \"Could not edit text. Please sample again or try with a different temperature setting, input, or instruction.\",\n",
       "        \"type\": \"invalid_edit\"\n",
       "      },\n",
       "      \"index\": 0\n",
       "    },\n",
       "    {\n",
       "      \"index\": 1,\n",
       "      \"text\": \"An attempt to paraphrase and be extremely verbose about it.\\n\"\n",
       "    },\n",
       "    {\n",
       "      \"index\": 2,\n",
       "      \"text\": \"Now you need to spend some time doing vertical exploration before you move on.\\n\"\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1649261390,\n",
       "  \"object\": \"edit\"\n",
       "}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fda8d31-cbb0-460c-abbd-ae8d8824cddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:20<00:00,  2.92s/it]\n"
     ]
    }
   ],
   "source": [
    "results = generate_alternative_wording(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9f08261-3027-4e42-9661-104a672c49f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOU SAY:  When you find something solid, use it, and let it expand horizontally into a whole environment.\n",
      "============================== MODEL SAYS: ==============================\n",
      "1 .  serious, problem with this approach is that it requires all the services\n",
      "2 .  important, reason for my visit to the island was because I wanted\n",
      "3 .  .\n",
      "\n",
      "\n",
      "\n",
      "Translate to English:\n",
      "\n",
      "\n",
      "\n",
      "The\n",
      "4 .  . You will be able to create a new room in the basement\n",
      "============================== END: ==============================\n",
      "YOU SAY:  These are quiet scenes Not silent but quiet You should have a short verbal exchange in each place.\n",
      "============================== MODEL SAYS: ==============================\n",
      "1 .  are not actors. They are real reenactors, who take\n",
      "2 .  are not actors. They are real reenactors of the Civil\n",
      "3 .  English: The characters should not speak in a whisper.\n",
      "\n",
      "Trans\n",
      "4 .  English:\n",
      "\n",
      " The characters should not speak in a whisper.\n",
      "============================== END: ==============================\n",
      "YOU SAY:  Hold on Slow down and make sure something happens that signals the beginning of a scene before you move on.\n",
      "============================== MODEL SAYS: ==============================\n",
      "1 .  the page is finished loading.\n",
      "\n",
      "This translation has been viewed 637 times\n",
      "2 .  the page is fully loaded.\n",
      "\n",
      "You are able to navigate through the pages\n",
      "3 .  hurry, the text in your clipboard will be automatically translated.\n",
      "4 .  hurry to buy the first car you see. The Internet is a great place for\n",
      "============================== END: ==============================\n",
      "YOU SAY:  Pure horizontal movement now Just tumble along.\n",
      "============================== MODEL SAYS: ==============================\n",
      "1 .  .\n",
      "\n",
      "The second movement\n",
      "2 .  , and I'm thinking about\n",
      "3 .  :\n",
      "\n",
      "\n",
      "\n",
      "Translate\n",
      "4 .  :\n",
      "\n",
      "\n",
      "\n",
      "Translate\n",
      "============================== END: ==============================\n",
      "YOU SAY:  I love this But help other people see what's going on Expand the physicality of each situation.\n",
      "============================== MODEL SAYS: ==============================\n",
      "1 .  to see the full text\n",
      "\n",
      "Hugh Grant and Colin F\n",
      "2 .  it\n",
      "3 .  I don't like that It's good for you I'm not\n",
      "4 .  ternut Squash Soup with Coconut Cream. You can make it\n",
      "============================== END: ==============================\n",
      "YOU SAY:  Now do some vertical exploration before you move on.\n",
      "============================== MODEL SAYS: ==============================\n",
      "1 .  Translate to French\n",
      "2 .  Translate to French\n",
      "3 .  , left, right) and go\n",
      "4 .  , left, or right) and\n",
      "============================== END: ==============================\n",
      "YOU SAY:  Be the over-enthusiastic, therapeutic host Everything the person requests, no matter how dry, is an opportunity to offer unsolicited therapy.\n",
      "============================== MODEL SAYS: ==============================\n",
      "1 .  ’ll bring you a glass of water.”\n",
      "\n",
      "\n",
      "Translate\n",
      "2 .  will give you a glass of water.”\n",
      "\n",
      "Translate to English\n",
      "3 .  I’m so anxious, too. I have a lot of anxiety about\n",
      "4 .  I’m so anxious about my job too. I’ve been\n",
      "============================== END: ==============================\n"
     ]
    }
   ],
   "source": [
    "for orig,gens in results:\n",
    "    print('YOU SAY: ', orig)    \n",
    "    print('='*30, 'MODEL SAYS:','='*30)\n",
    "    for i,gen in enumerate(gens):\n",
    "        print(i+1, '. ', gen)\n",
    "        \n",
    "    print('='*30, 'END:','='*30)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ac1abbd0-fd46-4269-895b-d95903f2691c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hold on. Slow down and make sure something happens that signals the beginning of a scene before you move on.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8af4f8e-a8ca-4a4c-8682-0dd0df7dff34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                  | 0/7 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "InvalidRequestError",
     "evalue": "Unrecognized request argument supplied: frequency_penalty",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m result \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(prompts):\n\u001b[1;32m----> 3\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEdit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext-davinci-edit-001\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43minstruction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mParaphrase extremely verbosely.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     texts \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m choice \u001b[38;5;129;01min\u001b[39;00m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchoices\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n",
      "File \u001b[1;32mc:\\users\\tornikeo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\openai\\api_resources\\edit.py:27\u001b[0m, in \u001b[0;36mEdit.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mcreate(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[1;32mc:\\users\\tornikeo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:105\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m     97\u001b[0m requestor \u001b[38;5;241m=\u001b[39m api_requestor\u001b[38;5;241m.\u001b[39mAPIRequestor(\n\u001b[0;32m     98\u001b[0m     api_key,\n\u001b[0;32m     99\u001b[0m     api_base\u001b[38;5;241m=\u001b[39mapi_base,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    102\u001b[0m     organization\u001b[38;5;241m=\u001b[39morganization,\n\u001b[0;32m    103\u001b[0m )\n\u001b[0;32m    104\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mclass_url(engine, api_type, api_version)\n\u001b[1;32m--> 105\u001b[0m response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    106\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)  \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\tornikeo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\openai\\api_requestor.py:120\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    103\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    109\u001b[0m     request_id: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    110\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    111\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[0;32m    112\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[0;32m    113\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    118\u001b[0m         request_id\u001b[38;5;241m=\u001b[39mrequest_id,\n\u001b[0;32m    119\u001b[0m     )\n\u001b[1;32m--> 120\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\users\\tornikeo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\openai\\api_requestor.py:327\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    321\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m         )\n\u001b[0;32m    323\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[0;32m    324\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 327\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m    329\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m     )\n",
      "File \u001b[1;32mc:\\users\\tornikeo\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\openai\\api_requestor.py:356\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    354\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 356\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[0;32m    357\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[0;32m    358\u001b[0m     )\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mInvalidRequestError\u001b[0m: Unrecognized request argument supplied: frequency_penalty"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for prompt in tqdm.tqdm(prompts):\n",
    "    response = openai.Edit.create(\n",
    "        engine=\"text-davinci-edit-001\",\n",
    "        input=prompt,\n",
    "        instruction=\"Paraphrase extremely verbosely.\",\n",
    "        temperature=1,\n",
    "        top_p=1,\n",
    "        frequency_penalty=1,\n",
    "        n=3,\n",
    "    )\n",
    "    texts = []\n",
    "    for choice in response['choices']:\n",
    "        if 'text' in choice.keys():\n",
    "            texts.append(choice['text'].strip())\n",
    "    result += [(prompt, texts)]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce4a469e-db7d-4f4b-8958-f7ef18b77701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOU SAY:  When you find something solid, use it, and let it expand horizontally into a whole environment.\n",
      "============================== MODEL SAYS: ==============================\n",
      "1 .  When you find it, use it, and let it spread horizontally along the full running time of your test if that's what it takes to find all the bugs.\n",
      "2 .  Let an environment grow out horizontally from an idea with what you can use that you can find.\n",
      "3 .  When you find something solid, use it, and let it expand horizontally into a whole environment.\n",
      "A single word is oftentimes stronger than the heaviest of hammers.\n",
      "============================== END: ==============================\n"
     ]
    }
   ],
   "source": [
    "for orig,gens in result:\n",
    "    print('YOU SAY: ', orig)    \n",
    "    print('='*30, 'MODEL SAYS:','='*30)\n",
    "    for i,gen in enumerate(gens):\n",
    "        print(i+1, '. ', gen)\n",
    "    print('='*30, 'END:','='*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3782a8a-99fb-4995-917c-5c262d98475d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
